{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFI42r81mNXS"
   },
   "source": [
    "# Analogue Library Preparation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook describes the systematic preparation of a small-molecule analogue library for subsequent QSAR modelling. Starting from a defined reference scaffold, structurally related compounds are curated and standardised to ensure chemical validity and structural consistency.\n",
    "\n",
    "The primary objective of this stage is to generate a chemically coherent dataset suitable for descriptor calculation and predictive modelling. All molecular representations are handled in SMILES format and validated using RDKit to ensure structural integrity and reproducibility.\n",
    "\n",
    "This step establishes the structural foundation of the QSAR pipeline and ensures methodological transparency prior to descriptor generation and model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrLjgfUTGaHW"
   },
   "source": [
    "**Step 1: Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1761581207348,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "0gnFN3af5gHL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr2DYNJJRcfM"
   },
   "source": [
    "**Step 2: Load Input Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "executionInfo": {
     "elapsed": 19930,
     "status": "ok",
     "timestamp": 1761581230857,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "vT26GA1I8t1L",
    "outputId": "72be9ba6-cd93-463a-89f2-1db803b414ed"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define data directory\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "# Define input file\n",
    "input_file = DATA_DIR / \"analogue_library_raw.csv\"\n",
    "\n",
    "# Verify file existence\n",
    "assert input_file.exists(), f\"Missing file: {input_file}\"\n",
    "\n",
    "print(\"Input dataset successfully located.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM1xMuh5RjgW"
   },
   "source": [
    "**Step 3: Import Dataset into DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1761581239299,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "Lh_pmOlZ8tx_"
   },
   "outputs": [],
   "source": [
    "# Load analogue library dataset\n",
    "analogue_df = pd.read_csv(input_file)\n",
    "\n",
    "# Display basic information\n",
    "analogue_df.info()\n",
    "\n",
    "analogue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYQE-kP-R1gD"
   },
   "source": [
    "**Step 4: Duplicate Structure Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1761581246301,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "nEae26-G8tr7",
    "outputId": "2a2d5b85-fc62-44f5-c3bd-966ff9137c91"
   },
   "outputs": [],
   "source": [
    "# Identify duplicate SMILES entries\n",
    "duplicate_mask = analogue_df.duplicated(subset=\"SMILES\", keep=False)\n",
    "duplicate_count = duplicate_mask.sum()\n",
    "\n",
    "print(f\"Number of duplicate structures detected: {duplicate_count}\")\n",
    "\n",
    "# Optional: Display duplicates if present\n",
    "if duplicate_count > 0:\n",
    "    analogue_df[duplicate_mask].sort_values(\"SMILES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b5dqqpKR-Z6"
   },
   "source": [
    "**Step 5: Identify and Display Duplicate Structures (Based on SMILES)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1761581251406,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "7bnj4j0-8tn6",
    "outputId": "a552cf3c-e6cc-41a7-a688-50af588f3200"
   },
   "outputs": [],
   "source": [
    "# Identify duplicate entries based on SMILES\n",
    "duplicate_rows = analogue_df[analogue_df.duplicated(subset=\"SMILES\", keep=False)]\n",
    "\n",
    "print(f\"Total duplicate structures identified: {len(duplicate_rows)}\")\n",
    "\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWVOV4gfSF3m"
   },
   "source": [
    "**Step 6: Remove Duplicate Structures and Irrelevant Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1761581266578,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "QVBOsGtZ8tkn",
    "outputId": "fe19f3b9-69c0-45d2-df9e-3f4872a3fce1"
   },
   "outputs": [],
   "source": [
    "# Remove duplicate structures based on SMILES\n",
    "initial_count = len(analogue_df)\n",
    "\n",
    "analogue_df = analogue_df.drop_duplicates(subset=\"SMILES\", keep=\"first\")\n",
    "\n",
    "final_count = len(analogue_df)\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(f\"Duplicate removal complete.\")\n",
    "print(f\"Structures removed: {removed_count}\")\n",
    "print(f\"Remaining structures: {final_count}\")\n",
    "\n",
    "# Remove non-essential columns if present\n",
    "if \"Similarity Score\" in analogue_df.columns:\n",
    "    analogue_df = analogue_df.drop(columns=[\"Similarity Score\"])\n",
    "    print(\"Column 'Similarity Score' removed.\")\n",
    "else:\n",
    "    print(\"Column 'Similarity Score' not present â€” no columns removed.\")\n",
    "\n",
    "analogue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqFV_ukJSMxR"
   },
   "source": [
    "**Step 7: Export Cleaned Analogue Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761581314117,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "kUGtvQ_E8the"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define output directory\n",
    "OUTPUT_DIR = Path(\"../data/processed\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define output file\n",
    "output_file = OUTPUT_DIR / \"analogue_library_cleaned.csv\"\n",
    "\n",
    "# Save cleaned dataset\n",
    "analogue_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned analogue library successfully saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GRVukM-SaQn"
   },
   "source": [
    "**Step 8: Final Dataset Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1761581334548,
     "user": {
      "displayName": "Jabir Nalicho",
      "userId": "08510785528384725113"
     },
     "user_tz": -180
    },
    "id": "XIjfOfS28td2",
    "outputId": "5d06934d-c577-4a02-836b-11ea93719075"
   },
   "outputs": [],
   "source": [
    "# Final dataset summary\n",
    "print(\"Final analogue library summary:\")\n",
    "print(f\"Total number of structures: {len(analogue_df)}\")\n",
    "print(f\"Number of columns: {analogue_df.shape[1]}\")\n",
    "\n",
    "print(\"\\nCleaned dataset is stored in the processed data directory.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzgaSuyx5Ztsvac5FoXVa0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
